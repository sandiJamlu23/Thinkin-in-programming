{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Capturing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import os\n",
    "import PIL as ImageGrab\n",
    "import pyautogui as py\n",
    "import pydirectinput\n",
    "import keyboard\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_screenshots(num_screenshots, delay=1, save_dir=\"screenshots\"):\n",
    "    # Create the directory if it doesn't exist\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    for i in range(num_screenshots):\n",
    "        # Capture screenshot\n",
    "        screenshot = py.screenshot(region=(5,30, 847, 542))\n",
    "        \n",
    "        # Save the screenshot to the specified directory with a unique filename\n",
    "        save_path = os.path.join(save_dir, f'screenshot_{i+1}.png')\n",
    "        screenshot.save(save_path)\n",
    "        \n",
    "        print(f'Screenshot {i+1} saved at {save_path}')\n",
    "        \n",
    "        # Add delay between screenshots\n",
    "        time.sleep(delay)\n",
    "    \n",
    "    print(f\"{num_screenshots} screenshots captured and saved in {save_dir}!\")\n",
    "\n",
    "# Example: Take 10 screenshots with a 1-second delay between each, store them in \"my_game_screenshots\" directory\n",
    "capture_screenshots(50, delay=1, save_dir=\"my_game_screenshots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[243, 243, 243],\n",
       "        [243, 243, 243],\n",
       "        [243, 243, 243],\n",
       "        ...,\n",
       "        [ 24,  24,  24],\n",
       "        [ 24,  24,  24],\n",
       "        [ 24,  24,  24]],\n",
       "\n",
       "       [[243, 243, 243],\n",
       "        [243, 243, 243],\n",
       "        [243, 243, 243],\n",
       "        ...,\n",
       "        [ 24,  24,  24],\n",
       "        [ 24,  24,  24],\n",
       "        [ 24,  24,  24]],\n",
       "\n",
       "       [[243, 243, 243],\n",
       "        [243, 243, 243],\n",
       "        [243, 243, 243],\n",
       "        ...,\n",
       "        [ 24,  24,  24],\n",
       "        [ 24,  24,  24],\n",
       "        [ 24,  24,  24]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 80, 148,  48],\n",
       "        [ 79, 144,  49],\n",
       "        [ 79, 146,  50],\n",
       "        ...,\n",
       "        [ 24,  24,  24],\n",
       "        [ 24,  24,  24],\n",
       "        [ 24,  24,  24]],\n",
       "\n",
       "       [[ 80, 140,  52],\n",
       "        [ 82, 142,  53],\n",
       "        [ 82, 144,  51],\n",
       "        ...,\n",
       "        [ 24,  24,  24],\n",
       "        [ 24,  24,  24],\n",
       "        [ 24,  24,  24]],\n",
       "\n",
       "       [[ 83, 140,  54],\n",
       "        [ 84, 140,  52],\n",
       "        [ 82, 140,  50],\n",
       "        ...,\n",
       "        [ 24,  24,  24],\n",
       "        [ 24,  24,  24],\n",
       "        [ 24,  24,  24]]], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def takeSS():\n",
    "    im = py.screenshot('image.png',region=(5,30, 847, 542))\n",
    "    # Change the format that OpenCV can understand\n",
    "    img = np.array(im)\n",
    "    img_cvt = cv.cvtColor(img, cv.COLOR_RGB2BGR)\n",
    "\n",
    "    # cv.imshow(\"das\", img_cvt)\n",
    "    # cv.waitKey(0)\n",
    "    # cv.destroyAllWindows()\n",
    "    return img_cvt\n",
    "\n",
    "takeSS()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple threshold for segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('D:/Thinkin in programming/Metopen/image.png', cv.IMREAD_GRAYSCALE)\n",
    "_, binary_image = cv.threshold(img, 127, 255, cv.THRESH_BINARY)\n",
    "\n",
    "cv.imshow('img',img)\n",
    "cv.waitKey(0)\n",
    "cv.imshow('global threshold',binary_image)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edge detection using Canny Edge Detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny_edge_detection(img):\n",
    "\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY )\n",
    "    kernel = 5\n",
    "    blur = cv.GaussianBlur(gray, (kernel, kernel),0)\n",
    "    canny = cv.Canny(blur, 50, 150)\n",
    "    \n",
    "    return canny\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the region of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roi(img):\n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "    \n",
    "    # Road mask\n",
    "    mask = np.zeros_like(img)\n",
    "    car_mask = np.zeros_like(img)\n",
    "    \n",
    "    # Define the coordinates for the trapezoid region\n",
    "    # Adjust these points based on the shape of the lane and the car's position\n",
    "    roi_points = np.array([\n",
    "    [((250), (250)),    # Top-left corner\n",
    "     ((600), (250)),    # Top-right corner     \n",
    "     ((800), (300)),    # Bottom-right corner\n",
    "     ((50),  (300))]    # Bottom-left corner    \n",
    "    ], np.int32)\n",
    "\n",
    "     # HARDCODE\n",
    "    # triangle = np.array([\n",
    "    # car_triangle = np.array([\n",
    "    #     [(int(width * 0.1), height),  # Bottom-left point\n",
    "    #      (int(width * 0.5), int(height * 0.5)),  # Top-middle point\n",
    "    #      (int(width * 0.9), height)]  # Bottom-right point\n",
    "    # ], np.int32)\n",
    "\n",
    "    # Fill the triangular region\n",
    "    cv.fillPoly(mask, roi_points, 255)\n",
    "    #cv.fillPoly(mask, [car_triangle],0)\n",
    "    \n",
    "    # Use bitwise_and to apply the mask\n",
    "    masked_image = cv.bitwise_and(img, mask)\n",
    "    \n",
    "    # cv.imshow(\"ROI Applied\", masked_image)\n",
    "    # cv.waitKey(0)\n",
    "    # cv.destroyAllWindows()\n",
    "    \n",
    "    return masked_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_road_roi(img):\n",
    "    height, width = img.shape[0], img.shape[1]\n",
    "\n",
    "    # Define a triangle that captures the road area in front of the car\n",
    "    # triangle = np.array([\n",
    "    #     [(int(width * 0.1), height),           # Bottom-left: 10% from the left of the frame\n",
    "    #      (int(width * 0.5), int(height * 0.6)), # Top-middle: center of the frame, 60% up\n",
    "    #      (int(width * 1.2), height)]           # Bottom-right: 90% from the left of the frame\n",
    "    # ], np.int32)\n",
    "    # HARDCODE\n",
    "    roi_points = np.array([\n",
    "    [((250), (250)),    # Top-left corner\n",
    "     ((600), (250)),    # Top-right corner     \n",
    "     ((800), (300)),    # Bottom-right corner\n",
    "     ((50),  (300))]    # Bottom-left corner    \n",
    "    ], np.int32)\n",
    "\n",
    "\n",
    "\n",
    "    # Draw the triangle on the image for visualization\n",
    "    cv.polylines(img, [roi_points], isClosed=True, color=(0, 255, 0), thickness=2)\n",
    "    return img\n",
    "\n",
    "# Example usage:\n",
    "img_cvt = takeSS()  # Capture screenshot and convert\n",
    "img_with_triangle = draw_road_roi(img_cvt)\n",
    "\n",
    "cv.imshow(\"Road Roi\", img_with_triangle)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coordinate Explanation:\n",
    "* (int(width * 0.1), height) defines the bottom-left point of the triangle (10% of the frame width from the left, and at the bottom).\n",
    "* (int(width * 0.5), int(height * 0.5)) is the top-middle point of the triangle (center of the width, and 50% down from the top).\n",
    "* (int(width * 0.9), height) is the bottom-right point of the triangle (90% of the frame width from the left, and at the bottom).\n",
    "How to Adjust the Triangle:\n",
    "Visually Inspect the Lane:\n",
    "\n",
    "Run the program and see where the triangle is placed. \n",
    "1. Adjust the width * 0.1 and width * 0.9 values to move the triangle left or right.\n",
    "2. Adjust height * 0.5 to raise or lower the top point of the triangle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the HLD (Hough Line Detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def houghlines(img):\n",
    "    hough_lines = cv.HoughLinesP(\n",
    "        img,\n",
    "        rho=6,  # Resolution of the accumulator in pixels\n",
    "        theta=np.pi / 100,  # Angle resolution in radians\n",
    "        threshold=150,  # Minimum number of intersecting points\n",
    "        minLineLength=30,  # Minimum length of a line\n",
    "        maxLineGap=10  # Maximum allowed gap between line segments\n",
    "    )\n",
    "    return hough_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as  cv\n",
    "\n",
    "# img = cv.imread('C:/Users/acer/Downloads/sudoku.png')\n",
    "img = cv.imread('D:/Thinkin in programming/Metopen/Roi_img.jpg')\n",
    "grays = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "blur = cv.GaussianBlur(grays, (5, 5),0)\n",
    "edges = cv.Canny(blur, 30,100,apertureSize=3)\n",
    "\n",
    "lines = cv.HoughLinesP(edges, 6, np.pi/80, threshold=100, minLineLength=40, maxLineGap=25)\n",
    "\n",
    "for line in lines:\n",
    "    x1,y1,x2,y2 = line[0]\n",
    "    cv.line(img,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "# lines = cv.HoughLines(edges,1,np.pi/180,100)\n",
    "# for rho,theta in lines[0]:\n",
    "#     a = np.cos(theta)\n",
    "#     b = np.sin(theta)\n",
    "#     x0 = a*rho\n",
    "#     y0 = b*rho\n",
    "#     x1 = int(x0 + 1000 * (-b))\n",
    "#     y1 = int(y0 + 1000 * (a))\n",
    "#     x2 = int(x0 - 1000 * (-b))\n",
    "#     y2 = int(y0 - 1000 * (a))\n",
    "\n",
    "#     cv.line(img, (x1,y1), (x2,y2),(0,0,255),2)\n",
    "\n",
    "cv.imshow(\"line\",img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with the following arguments:\n",
    "* dst: Output of the edge detector. It should be a grayscale image (although in fact it is a binary one)\n",
    "* lines: A vector that will store the parameters (r,θ) of the detected lines\n",
    "* rho : The resolution of the parameter r in pixels. We use 1 pixel.\n",
    "* theta: The resolution of the parameter θ in radians. We use 1 degree (CV_PI/180)\n",
    "* threshold: The minimum number of intersections to \"*detect*\" a line\n",
    "* srn and stn: Default parameters to zero. Check OpenCV reference for more info."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perspective Correction (https://medium.com/nerd-for-tech/lane-detection-with-opencv-part-1-ad9ea5758c07)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we were flying over the road, and watching it from a bird’s eye view, the lanes would be parallel, but in the picture, they are not, because of the perspective.\n",
    "The perspective depends on the focal length of the lens (lenses with a shorter focal length show a stronger perspective) and the position of the camera. Once the camera is mounted on a car, the perspective is fixed, so we can take it into consideration and correct the image.\n",
    "OpenCV has a method to compute the perspective transformation:\n",
    "**getPerspectiveTransform().**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_points(img, lineSI):\n",
    "    slope, intercept = lineSI\n",
    "    # height = roi_bottom  # Use the bottom coordinate of the ROI\n",
    "    y1 = int(img.shape[0])  # Bottom of the ROI\n",
    "    y2 = int(y1 * 0.5)  # Extend the line slightly beyond the bottom of the ROI\n",
    "\n",
    "    # Calculate x coordinates based on slope and intercept\n",
    "    x1 = int((y1 - intercept) / slope)\n",
    "    x2 = int((y2 - intercept) / slope)\n",
    "\n",
    "    return [[x1, y1, x2, y2]]  # Return the points in the format required by cv.line\n",
    "\n",
    "\n",
    "# Before running this code below, you need to make sure that the line of the lane and the car\n",
    "# is already correct. Specify the correct region of interest first\n",
    "def average_slope_intercepts(img, lines):\n",
    "    left_fit = []\n",
    "    right_fit = []\n",
    "    \n",
    "    if lines is None:\n",
    "        return None\n",
    "    \n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            # Check for a valid line length (avoid horizontal/vertical short lines)\n",
    "            fit = np.polyfit((x1, x2), (y1, y2), 1)\n",
    "            slope = fit[0]\n",
    "            intercept = fit[1]\n",
    "            # Filter based on slope: negative for left, positive for right\n",
    "            if slope < 0:  # Left lane\n",
    "                left_fit.append((slope, intercept))\n",
    "            elif slope > 0:  # Right lane\n",
    "                right_fit.append((slope, intercept))\n",
    "            # if abs(x2 - x1) > 0 and abs(y2 - y1) > 0:  \n",
    "                \n",
    "    left_fit_average  = np.average(left_fit, axis=0)\n",
    "    right_fit_average = np.average(right_fit, axis=0)\n",
    "    left_line  = make_points(img, left_fit_average)\n",
    "    right_line = make_points(img, right_fit_average)\n",
    "    average_lines = [left_line, right_line]\n",
    "    # # Average fits\n",
    "    # if left_fit:\n",
    "    #     left_fit_average = np.average(left_fit, axis=0)\n",
    "    # else:\n",
    "    #     left_fit_average = None\n",
    "\n",
    "    # if right_fit:\n",
    "    #     right_fit_average = np.average(right_fit, axis=0)\n",
    "    # else:\n",
    "    #     right_fit_average = None\n",
    "\n",
    "    # # Generate lines only if averages are available\n",
    "    # average_lines = []\n",
    "    # if left_fit_average is not None:\n",
    "    #     left_line = make_points(img, left_fit_average, roi_bottom)\n",
    "    #     average_lines.append(left_line)\n",
    "    # if right_fit_average is not None:\n",
    "    #     right_line = make_points(img, right_fit_average, roi_bottom)\n",
    "    #     average_lines.append(right_line)\n",
    "\n",
    "    return average_lines\n",
    "\n",
    "\n",
    "def display_lines_average(img, lines):\n",
    "    # line_image = [0]\n",
    "    line_image = np.zeros_like(img)\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            for x1, y1, x2, y2 in line:\n",
    "                cv.line(line_image, (x1,y1), (x2,y2), (0,0,255),10)\n",
    "    # return img\n",
    "    return line_image\n",
    "\n",
    "# img = takeSS()\n",
    "img = cv.imread(\"D:/Thinkin in programming/Metopen/my_game_screenshots/screenshot_5.png\")\n",
    "image = np.copy(img)\n",
    "canny_image = canny_edge_detection(image)\n",
    "masked_image =  roi(canny_image)\n",
    "h_lines = houghlines(masked_image)\n",
    "\n",
    "# Call the line function\n",
    "avg_lines = average_slope_intercepts(img, h_lines)\n",
    "lines_image = display_lines_average(image, avg_lines)\n",
    "\n",
    "# print(avg_lines)\n",
    "# print(h_lines)\n",
    "merge_image = cv.addWeighted(img, 0.8, lines_image, 1,1)\n",
    "cv.imshow(\"result\",merge_image)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "# cv.imshow(\"win\",lines_image)\n",
    "# cv.imshow(\"win\",canny_image)\n",
    "# cv.waitKey(0)\n",
    "# cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def average_slope_intercepts(img, lines):\n",
    "\n",
    "sometimes(in most cases actually) it detects multiple lines.  to overcome this, we can use the average value within the lines as you’ve seen in this code.\n",
    "\n",
    "bear in minds that, the lines (you can see at the ros function) is a lot of them. So you need to specify that only certain lines that is captured, hence it is called region of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turn Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(542, 847, 3)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pyautogui as py\n",
    "import pydirectinput\n",
    "\n",
    "# Function to click at specified coordinates (using PyAutoGUI)\n",
    "def click(x, y):\n",
    "    py.click(x, y)  # Click at the specified coordinates\n",
    "    time.sleep(0.5)  # Wait briefly to ensure the game is focused\n",
    "    \n",
    "def accelerate(hold_time):\n",
    "    start = time.time()\n",
    "    while time.time() - start < hold_time:\n",
    "        pydirectinput.keyDown('up')\n",
    "    pydirectinput.keyUp('up')\n",
    "\n",
    "def turnLeft(hold_time):\n",
    "    start = time.time()\n",
    "    while time.time() - start < hold_time:\n",
    "        pydirectinput.keyDown('a')\n",
    "    pydirectinput.keyUp('a')\n",
    "\n",
    "def turnRight(hold_time):\n",
    "    start = time.time()\n",
    "    while time.time() - start < hold_time:\n",
    "        pydirectinput.keyDown('d')\n",
    "    pydirectinput.keyUp('d')\n",
    "\n",
    "# Accelerate for 10 seconds, then turn left and right\n",
    "click(409, 275)\n",
    "accelerate(10)\n",
    "turnLeft(0.3)\n",
    "turnRight(0.3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
