{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Capturing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import os\n",
    "import PIL as ImageGrab\n",
    "import pyautogui as py\n",
    "import keyboard\n",
    "import time\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Screenshot 1 saved at my_game_screenshots\\screenshot_1.png\n",
      "Screenshot 2 saved at my_game_screenshots\\screenshot_2.png\n",
      "Screenshot 3 saved at my_game_screenshots\\screenshot_3.png\n",
      "Screenshot 4 saved at my_game_screenshots\\screenshot_4.png\n",
      "Screenshot 5 saved at my_game_screenshots\\screenshot_5.png\n",
      "Screenshot 6 saved at my_game_screenshots\\screenshot_6.png\n",
      "Screenshot 7 saved at my_game_screenshots\\screenshot_7.png\n",
      "Screenshot 8 saved at my_game_screenshots\\screenshot_8.png\n",
      "Screenshot 9 saved at my_game_screenshots\\screenshot_9.png\n",
      "Screenshot 10 saved at my_game_screenshots\\screenshot_10.png\n",
      "Screenshot 11 saved at my_game_screenshots\\screenshot_11.png\n",
      "Screenshot 12 saved at my_game_screenshots\\screenshot_12.png\n",
      "Screenshot 13 saved at my_game_screenshots\\screenshot_13.png\n",
      "Screenshot 14 saved at my_game_screenshots\\screenshot_14.png\n",
      "Screenshot 15 saved at my_game_screenshots\\screenshot_15.png\n",
      "Screenshot 16 saved at my_game_screenshots\\screenshot_16.png\n",
      "Screenshot 17 saved at my_game_screenshots\\screenshot_17.png\n",
      "Screenshot 18 saved at my_game_screenshots\\screenshot_18.png\n",
      "Screenshot 19 saved at my_game_screenshots\\screenshot_19.png\n",
      "Screenshot 20 saved at my_game_screenshots\\screenshot_20.png\n",
      "Screenshot 21 saved at my_game_screenshots\\screenshot_21.png\n",
      "Screenshot 22 saved at my_game_screenshots\\screenshot_22.png\n",
      "Screenshot 23 saved at my_game_screenshots\\screenshot_23.png\n",
      "Screenshot 24 saved at my_game_screenshots\\screenshot_24.png\n",
      "Screenshot 25 saved at my_game_screenshots\\screenshot_25.png\n",
      "Screenshot 26 saved at my_game_screenshots\\screenshot_26.png\n",
      "Screenshot 27 saved at my_game_screenshots\\screenshot_27.png\n",
      "Screenshot 28 saved at my_game_screenshots\\screenshot_28.png\n",
      "Screenshot 29 saved at my_game_screenshots\\screenshot_29.png\n",
      "Screenshot 30 saved at my_game_screenshots\\screenshot_30.png\n",
      "Screenshot 31 saved at my_game_screenshots\\screenshot_31.png\n",
      "Screenshot 32 saved at my_game_screenshots\\screenshot_32.png\n",
      "Screenshot 33 saved at my_game_screenshots\\screenshot_33.png\n",
      "Screenshot 34 saved at my_game_screenshots\\screenshot_34.png\n",
      "Screenshot 35 saved at my_game_screenshots\\screenshot_35.png\n",
      "Screenshot 36 saved at my_game_screenshots\\screenshot_36.png\n",
      "Screenshot 37 saved at my_game_screenshots\\screenshot_37.png\n",
      "Screenshot 38 saved at my_game_screenshots\\screenshot_38.png\n",
      "Screenshot 39 saved at my_game_screenshots\\screenshot_39.png\n",
      "Screenshot 40 saved at my_game_screenshots\\screenshot_40.png\n",
      "Screenshot 41 saved at my_game_screenshots\\screenshot_41.png\n",
      "Screenshot 42 saved at my_game_screenshots\\screenshot_42.png\n",
      "Screenshot 43 saved at my_game_screenshots\\screenshot_43.png\n",
      "Screenshot 44 saved at my_game_screenshots\\screenshot_44.png\n",
      "Screenshot 45 saved at my_game_screenshots\\screenshot_45.png\n",
      "Screenshot 46 saved at my_game_screenshots\\screenshot_46.png\n",
      "Screenshot 47 saved at my_game_screenshots\\screenshot_47.png\n",
      "Screenshot 48 saved at my_game_screenshots\\screenshot_48.png\n",
      "Screenshot 49 saved at my_game_screenshots\\screenshot_49.png\n",
      "Screenshot 50 saved at my_game_screenshots\\screenshot_50.png\n",
      "50 screenshots captured and saved in my_game_screenshots!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def capture_screenshots(num_screenshots, delay=1, save_dir=\"screenshots\"):\n",
    "    # Create the directory if it doesn't exist\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    for i in range(num_screenshots):\n",
    "        # Capture screenshot\n",
    "        screenshot = py.screenshot(region=(5,30, 847, 542))\n",
    "        \n",
    "        # Save the screenshot to the specified directory with a unique filename\n",
    "        save_path = os.path.join(save_dir, f'screenshot_{i+1}.png')\n",
    "        screenshot.save(save_path)\n",
    "        \n",
    "        print(f'Screenshot {i+1} saved at {save_path}')\n",
    "        \n",
    "        # Add delay between screenshots\n",
    "        time.sleep(delay)\n",
    "    \n",
    "    print(f\"{num_screenshots} screenshots captured and saved in {save_dir}!\")\n",
    "\n",
    "# Example: Take 10 screenshots with a 1-second delay between each, store them in \"my_game_screenshots\" directory\n",
    "capture_screenshots(50, delay=1, save_dir=\"my_game_screenshots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 32,  32,  32],\n",
       "        [ 32,  32,  32],\n",
       "        [ 32,  32,  32],\n",
       "        ...,\n",
       "        [ 32,  32,  32],\n",
       "        [ 32,  32,  32],\n",
       "        [ 32,  32,  32]],\n",
       "\n",
       "       [[ 32,  32,  32],\n",
       "        [ 32,  32,  32],\n",
       "        [ 32,  32,  32],\n",
       "        ...,\n",
       "        [ 32,  32,  32],\n",
       "        [ 32,  32,  32],\n",
       "        [ 32,  32,  32]],\n",
       "\n",
       "       [[ 32,  32,  32],\n",
       "        [ 32,  32,  32],\n",
       "        [ 32,  32,  32],\n",
       "        ...,\n",
       "        [ 32,  32,  32],\n",
       "        [ 32,  32,  32],\n",
       "        [ 32,  32,  32]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 59,  59,  59],\n",
       "        [ 59,  59,  59],\n",
       "        [ 59,  59,  59],\n",
       "        ...,\n",
       "        [250, 250, 249],\n",
       "        [250, 250, 249],\n",
       "        [250, 250, 249]],\n",
       "\n",
       "       [[ 59,  59,  59],\n",
       "        [ 59,  59,  59],\n",
       "        [ 59,  59,  59],\n",
       "        ...,\n",
       "        [250, 250, 249],\n",
       "        [250, 250, 249],\n",
       "        [250, 250, 249]],\n",
       "\n",
       "       [[ 59,  59,  59],\n",
       "        [ 59,  59,  59],\n",
       "        [ 59,  59,  59],\n",
       "        ...,\n",
       "        [250, 250, 249],\n",
       "        [250, 250, 249],\n",
       "        [250, 250, 249]]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def takeSS():\n",
    "    im = py.screenshot('image.png',region=(5,30, 847, 542))\n",
    "    # Change the format that OpenCV can understand\n",
    "    img = np.array(im)\n",
    "    img_cvt = cv.cvtColor(img, cv.COLOR_RGB2BGR)\n",
    "\n",
    "    # cv.imshow(\"das\", img_cvt)\n",
    "    # cv.waitKey(0)\n",
    "    # cv.destroyAllWindows()\n",
    "    return img_cvt\n",
    "\n",
    "takeSS()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple threshold for segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('D:/Thinkin in programming/Metopen/image.png', cv.IMREAD_GRAYSCALE)\n",
    "_, binary_image = cv.threshold(img, 127, 255, cv.THRESH_BINARY)\n",
    "\n",
    "cv.imshow('img',img)\n",
    "cv.waitKey(0)\n",
    "cv.imshow('global threshold',binary_image)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edge detection using Canny Edge Detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny_edge_detection(img_cvt):\n",
    "    gray = cv.cvtColor(img_cvt, cv.COLOR_BGR2GRAY )\n",
    "    kernel = 5\n",
    "    blur = cv.GaussianBlur(gray, (kernel, kernel),0)\n",
    "    canny = cv.Canny(blur, 50, 150)\n",
    "    return canny\n",
    "\n",
    "img = takeSS()\n",
    "can = canny_edge_detection(img)\n",
    "\n",
    "# cv.imwrite(\"canny.jpg\",can)\n",
    "\n",
    "cv.imshow(\"can\", can)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the region of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roi(img):\n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "    \n",
    "    # Road mask\n",
    "    mask = np.zeros_like(img)\n",
    "    car_mask = np.zeros_like(img)\n",
    "    \n",
    "    # Define the coordinates for the trapezoid region\n",
    "    # Adjust these points based on the shape of the lane and the car's position\n",
    "    roi_points = np.array([\n",
    "    [((250), (250)),    # Top-left corner\n",
    "     ((600), (250)),    # Top-right corner     \n",
    "     ((800), (300)),    # Bottom-right corner\n",
    "     ((50),  (300))]    # Bottom-left corner    \n",
    "    ], np.int32)\n",
    "\n",
    "     # HARDCODE\n",
    "    # triangle = np.array([\n",
    "    # car_triangle = np.array([\n",
    "    #     [(int(width * 0.1), height),  # Bottom-left point\n",
    "    #      (int(width * 0.5), int(height * 0.5)),  # Top-middle point\n",
    "    #      (int(width * 0.9), height)]  # Bottom-right point\n",
    "    # ], np.int32)\n",
    "\n",
    "    # Fill the triangular region\n",
    "    cv.fillPoly(mask, roi_points, 255)\n",
    "    #cv.fillPoly(mask, [car_triangle],0)\n",
    "    \n",
    "    # Use bitwise_and to apply the mask\n",
    "    masked_image = cv.bitwise_and(img, mask)\n",
    "    \n",
    "    cv.imshow(\"ROI Applied\", masked_image)\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()\n",
    "    \n",
    "    return masked_image\n",
    "\n",
    "#Example usage:\n",
    "img_cvt = takeSS()  # Capture screenshot and convert\n",
    "edges = canny_edge_detection(img_cvt)  # Perform Canny edge detection\n",
    "masked_image = roi(edges)\n",
    "\n",
    "cv.imwrite(\"Roi_img.jpg\", masked_image)\n",
    "cv.imshow(\"Masked Image\", masked_image)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For future adjustment, use trapezoid instead of triangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_road_roi(img):\n",
    "    height, width = img.shape[0], img.shape[1]\n",
    "\n",
    "    # Define a triangle that captures the road area in front of the car\n",
    "    # triangle = np.array([\n",
    "    #     [(int(width * 0.1), height),           # Bottom-left: 10% from the left of the frame\n",
    "    #      (int(width * 0.5), int(height * 0.6)), # Top-middle: center of the frame, 60% up\n",
    "    #      (int(width * 1.2), height)]           # Bottom-right: 90% from the left of the frame\n",
    "    # ], np.int32)\n",
    "    # HARDCODE\n",
    "    roi_points = np.array([\n",
    "    [((250), (250)),    # Top-left corner\n",
    "     ((600), (250)),    # Top-right corner     \n",
    "     ((800), (300)),    # Bottom-right corner\n",
    "     ((50),  (300))]    # Bottom-left corner    \n",
    "    ], np.int32)\n",
    "\n",
    "\n",
    "\n",
    "    # Draw the triangle on the image for visualization\n",
    "    cv.polylines(img, [roi_points], isClosed=True, color=(0, 255, 0), thickness=2)\n",
    "    return img\n",
    "\n",
    "# Example usage:\n",
    "img_cvt = takeSS()  # Capture screenshot and convert\n",
    "img_with_triangle = draw_road_roi(img_cvt)\n",
    "\n",
    "\n",
    "cv.imshow(\"Road Roi\", img_with_triangle)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coordinate Explanation:\n",
    "* (int(width * 0.1), height) defines the bottom-left point of the triangle (10% of the frame width from the left, and at the bottom).\n",
    "* (int(width * 0.5), int(height * 0.5)) is the top-middle point of the triangle (center of the width, and 50% down from the top).\n",
    "* (int(width * 0.9), height) is the bottom-right point of the triangle (90% of the frame width from the left, and at the bottom).\n",
    "How to Adjust the Triangle:\n",
    "Visually Inspect the Lane:\n",
    "\n",
    "Run the program and see where the triangle is placed. \n",
    "1. Adjust the width * 0.1 and width * 0.9 values to move the triangle left or right.\n",
    "2. Adjust height * 0.5 to raise or lower the top point of the triangle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the HLD (Hough Line Detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def houghlines(img):\n",
    "    hough_lines = cv.HoughLinesP(\n",
    "        img,\n",
    "        rho=6,  # Resolution of the accumulator in pixels\n",
    "        theta=np.pi / 100,  # Angle resolution in radians\n",
    "        threshold=150,  # Minimum number of intersecting points\n",
    "        minLineLength=30,  # Minimum length of a line\n",
    "        maxLineGap=10  # Maximum allowed gap between line segments\n",
    "    )\n",
    "    return hough_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRY THIS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as  cv\n",
    "\n",
    "# img = cv.imread('C:/Users/acer/Downloads/sudoku.png')\n",
    "img = cv.imread('D:/Thinkin in programming/Metopen/Roi_img.jpg')\n",
    "grays = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "blur = cv.GaussianBlur(grays, (5, 5),0)\n",
    "edges = cv.Canny(blur, 30,100,apertureSize=3)\n",
    "\n",
    "lines = cv.HoughLinesP(edges, 6, np.pi/80, threshold=100, minLineLength=40, maxLineGap=25)\n",
    "\n",
    "for line in lines:\n",
    "    x1,y1,x2,y2 = line[0]\n",
    "    cv.line(img,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "# lines = cv.HoughLines(edges,1,np.pi/180,100)\n",
    "# for rho,theta in lines[0]:\n",
    "#     a = np.cos(theta)\n",
    "#     b = np.sin(theta)\n",
    "#     x0 = a*rho\n",
    "#     y0 = b*rho\n",
    "#     x1 = int(x0 + 1000 * (-b))\n",
    "#     y1 = int(y0 + 1000 * (a))\n",
    "#     x2 = int(x0 - 1000 * (-b))\n",
    "#     y2 = int(y0 - 1000 * (a))\n",
    "\n",
    "#     cv.line(img, (x1,y1), (x2,y2),(0,0,255),2)\n",
    "\n",
    "cv.imshow(\"line\",img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with the following arguments:\n",
    "* dst: Output of the edge detector. It should be a grayscale image (although in fact it is a binary one)\n",
    "* lines: A vector that will store the parameters (r,θ) of the detected lines\n",
    "* rho : The resolution of the parameter r in pixels. We use 1 pixel.\n",
    "* theta: The resolution of the parameter θ in radians. We use 1 degree (CV_PI/180)\n",
    "* threshold: The minimum number of intersections to \"*detect*\" a line\n",
    "* srn and stn: Default parameters to zero. Check OpenCV reference for more info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[490, 300, 385, 450]], [[517, 300, 679, 450]]]\n",
      "[[[455 208 846 312]]\n",
      "\n",
      " [[500 209 752 244]]\n",
      "\n",
      " [[ 44  86 125 110]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[226 225 256 222]]\n",
      "\n",
      " [[780 310 841 329]]\n",
      "\n",
      " [[790 249 827 254]]]\n"
     ]
    }
   ],
   "source": [
    "def make_points(img, lineSI, roi_bottom):\n",
    "    slope, intercept = lineSI\n",
    "    height = roi_bottom  # Use the bottom coordinate of the ROI\n",
    "    y1 = int(height)  # Bottom of the ROI\n",
    "    y2 = int(y1 * 1.5)  # Extend the line slightly beyond the bottom of the ROI\n",
    "\n",
    "    # Calculate x coordinates based on slope and intercept\n",
    "    x1 = int((y1 - intercept) / slope)\n",
    "    x2 = int((y2 - intercept) / slope)\n",
    "\n",
    "    return [[x1, y1, x2, y2]]  # Return the points in the format required by cv.line\n",
    "\n",
    "\n",
    "# Before running this code below, you need to make sure that the line of the lane and the car\n",
    "# is already correct. Specify the correct region of interest first\n",
    "def average_slope_intercepts(img, lines, roi_bottom):\n",
    "    left_fit = []\n",
    "    right_fit = []\n",
    "    \n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            # Check for a valid line length (avoid horizontal/vertical short lines)\n",
    "            if abs(x2 - x1) > 0 and abs(y2 - y1) > 0:  \n",
    "                fit = np.polyfit((x1, x2), (y1, y2), 1)\n",
    "                slope = fit[0]\n",
    "                intercept = fit[1]\n",
    "\n",
    "                # Filter based on slope: negative for left, positive for right\n",
    "                if slope < 0:  # Left lane\n",
    "                    left_fit.append((slope, intercept))\n",
    "                elif slope > 0:  # Right lane\n",
    "                    right_fit.append((slope, intercept))\n",
    "\n",
    "    # Average fits\n",
    "    if left_fit:\n",
    "        left_fit_average = np.average(left_fit, axis=0)\n",
    "    else:\n",
    "        left_fit_average = None\n",
    "\n",
    "    if right_fit:\n",
    "        right_fit_average = np.average(right_fit, axis=0)\n",
    "    else:\n",
    "        right_fit_average = None\n",
    "\n",
    "    # Generate lines only if averages are available\n",
    "    average_lines = []\n",
    "    if left_fit_average is not None:\n",
    "        left_line = make_points(img, left_fit_average, roi_bottom)\n",
    "        average_lines.append(left_line)\n",
    "    if right_fit_average is not None:\n",
    "        right_line = make_points(img, right_fit_average, roi_bottom)\n",
    "        average_lines.append(right_line)\n",
    "\n",
    "    return average_lines\n",
    "\n",
    "\n",
    "def display_lines_average(img, lines):\n",
    "    line_image = [0]\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            for x1, y1, x2, y2 in line:\n",
    "                cv.line(img, (x1,y1), (x2,y2), (0,0,255),10)\n",
    "    return img\n",
    "h_lines = houghlines(edges)\n",
    "\n",
    "# Call the line function\n",
    "roi_bottom = 300\n",
    "avg_lines = average_slope_intercepts(img_cvt, h_lines, roi_bottom)\n",
    "print(avg_lines)\n",
    "print(h_lines)\n",
    "\n",
    "lines_image = display_lines_average(img_cvt, avg_lines)\n",
    "cv.imshow(\"Detected Lines\", lines_image)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def average_slope_intercepts(img, lines):\n",
    "\n",
    "sometimes(in most cases actually) it detects multiple lines.  to overcome this, we can use the average value within the lines as you’ve seen in this code.\n",
    "\n",
    "bear in minds that, the lines (you can see at the ros function) is a lot of them. So you need to specify that only certain lines that is captured, hence it is called region of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Controlling the car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pyautogui as py\n",
    "import pydirectinput\n",
    "\n",
    "# Function to click at specified coordinates (using PyAutoGUI)\n",
    "def click(x, y):\n",
    "    py.click(x, y)  # Click at the specified coordinates\n",
    "    time.sleep(0.5)  # Wait briefly to ensure the game is focused\n",
    "    \n",
    "def accelerate(hold_time):\n",
    "    start = time.time()\n",
    "    while time.time() - start < hold_time:\n",
    "        pydirectinput.keyDown('up')\n",
    "    pydirectinput.keyUp('up')\n",
    "\n",
    "def turnLeft(hold_time):\n",
    "    start = time.time()\n",
    "    while time.time() - start < hold_time:\n",
    "        pydirectinput.keyDown('a')\n",
    "    pydirectinput.keyUp('a')\n",
    "\n",
    "def turnRight(hold_time):\n",
    "    start = time.time()\n",
    "    while time.time() - start < hold_time:\n",
    "        pydirectinput.keyDown('d')\n",
    "    pydirectinput.keyUp('d')\n",
    "\n",
    "# Accelerate for 10 seconds, then turn left and right\n",
    "click(409, 275)\n",
    "accelerate(10)\n",
    "turnLeft(0.3)\n",
    "turnRight(0.3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
